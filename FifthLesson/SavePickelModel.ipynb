{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from time import time\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, log_loss\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import graphviz\n",
    "import pickle\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessdataframe (df):\n",
    "    imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "    imputer = imputer.fit(df.loc[:,['Age']])\n",
    "    df.loc[:,'Age'] = imputer.transform(df.loc[:,['Age']])\n",
    "\n",
    "    imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "    imputer = imputer.fit(df.loc[:,['Fare']])\n",
    "    df.loc[:,'Fare'] = imputer.transform(df.loc[:,['Fare']])\n",
    "\n",
    "    df.Embarked = df.Embarked.fillna('S')\n",
    "\n",
    "    df = pd.get_dummies(data=df, columns=['Embarked', 'Pclass', 'Sex'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showroccurve(fpr, tpr, roc_auc, label, color):\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color=color,\n",
    "             lw=lw, label='ROC curve - {0} (area = {1:0.2f})'.format(label, roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showmultiroccurve(params): #this should be a list of dictionaries of fpr, tpr, roc_auc, label, and color\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    for param in params:\n",
    "        plt.plot(param[\"fpr\"], param[\"tpr\"], color=param[\"color\"],\n",
    "             lw=lw, label='ROC curve - {0} (area = {1:0.2f})'.format(param[\"label\"],param[\"roc_auc\"]))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showdecisiontree(model, feature_names, name):\n",
    "    dot_data = tree.export_graphviz(model, out_file=None,\n",
    "         feature_names=feature_names,\n",
    "         class_names=['Did not survive', 'Survived'],\n",
    "         filled=True, rounded=True,\n",
    "         special_characters=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    graph.render(name)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_save(name, item):\n",
    "    PIK = str(name)+ \".pickle\"\n",
    "    with open(PIK,\"wb\") as f:\n",
    "        pickle.dump(item, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_load(name):\n",
    "    PIK = str(name) + \".pickle\"\n",
    "    with open(PIK,\"rb\") as f:\n",
    "        temp_item = pickle.load(f)\n",
    "    return temp_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features = ['Age', 'Fare']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(missing_values = np.nan, strategy = 'mean'))])\n",
    "#,    ('scaler', StandardScaler()) --pulled this out\n",
    "\n",
    "categorical_features = ['Embarked', 'Sex', 'Pclass']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier(n_estimators= 500, min_samples_split = 0.01, min_samples_leaf = 0.1, min_impurity_decrease = 0.0001, max_features = 3, max_depth = 4))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('~/Documents/GitHub/TiberDataScienceLearning/Data/Titanic/train.csv')\n",
    "y = df[['Survived']]\n",
    "x = df[['Pclass','Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.fit(x, y['Survived'])\n",
    "pickle_save(\"mymodel\", model)\n",
    "#pickle_save(\"~/Documents/GitHub/TiberDataScienceLearning/FifthLesson/mymodel\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
